{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JensH-2157843/AML_Project/blob/main/src/neural_networks/NN1(segmentation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library imports"
      ],
      "metadata": {
        "id": "Um0i7fD1wrYv"
      },
      "id": "Um0i7fD1wrYv"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models==1.0.1 albumentations==1.3.1 --quiet\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import SegformerFeatureExtractor\n",
        "\n",
        "import time\n",
        "import copy\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NABThOXpwtiG",
        "outputId": "8af562e2-424c-4d5b-a5a5-761f71816cf0"
      },
      "id": "NABThOXpwtiG",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset import"
      ],
      "metadata": {
        "id": "903c_9H44Wfs"
      },
      "id": "903c_9H44Wfs"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LlRduzl82rms",
        "outputId": "95cc4345-d17b-4ed3-a06f-f030ca53b663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LlRduzl82rms",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DATASET IMPORT ##\n",
        "deepglobe_dir = \"/content/drive/MyDrive/train\"\n",
        "import os\n",
        "\n",
        "deepglobe_images = sorted(glob(os.path.join(deepglobe_dir, '*_sat.jpg')))\n",
        "deepglobe_masks = sorted(glob(os.path.join(deepglobe_dir, '*_mask.png')))\n",
        "\n",
        "for tile in sorted(os.listdir(deepglobe_dir)):\n",
        "    tile_path = os.path.join(deepglobe_dir, tile)\n",
        "    if not os.path.isdir(tile_path):\n",
        "        continue\n",
        "    img_folder = os.path.join(tile_path, \"images\")\n",
        "    mask_folder = os.path.join(tile_path, \"masks\")\n",
        "    deepglobe_images.extend(sorted(glob(os.path.join(img_folder, '*.jpg'))))\n",
        "    deepglobe_masks.extend(sorted(glob(os.path.join(mask_folder, '*.png'))))\n",
        "\n",
        "all_images = deepglobe_images\n",
        "all_masks = deepglobe_masks\n",
        "\n",
        "train_imgs, val_imgs, train_masks, val_masks = train_test_split(\n",
        "    all_images, all_masks, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "LA8Iaee_wwtJ"
      },
      "id": "LA8Iaee_wwtJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "def rgb_to_binary_mask(mask_image, suitable_rgbs):\n",
        "    mask = np.array(mask_image)\n",
        "    binary_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int64)\n",
        "    for rgb in suitable_rgbs:\n",
        "        matches = np.all(mask == rgb, axis=-1)\n",
        "        binary_mask[matches] = 1\n",
        "    return binary_mask\n",
        "\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "mask_transforms = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE, interpolation=transforms.InterpolationMode.NEAREST)\n",
        "])"
      ],
      "metadata": {
        "id": "71Pb4N7C6fu7"
      },
      "id": "71Pb4N7C6fu7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Your PyTorch Dataset (This IS your combined loader + preprocessor) ---\n",
        "class SolarPanelDataset(Dataset):\n",
        "    def __init__(self, img_paths, mask_paths, suitable_rgbs, img_transform=None, mask_transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.suitable_rgbs = suitable_rgbs\n",
        "        self.img_transform = img_transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # --- Start of Preprocessing Logic (PyTorch version) ---\n",
        "        img_path = self.img_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask_rgb = Image.open(mask_path).convert(\"RGB\")\n",
        "        if self.img_transform:\n",
        "            image = self.img_transform(image) # Applies resize, ToTensor, Normalize\n",
        "        if self.mask_transform:\n",
        "            mask_rgb = self.mask_transform(mask_rgb) # Applies resize (NEAREST)\n",
        "        mask_binary = rgb_to_binary_mask(mask_rgb, self.suitable_rgbs) # Converts mask\n",
        "        mask = torch.from_numpy(mask_binary) # To PyTorch Tensor\n",
        "        # --- End of Preprocessing Logic ---\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "EB3qzu3R6j4O"
      },
      "id": "EB3qzu3R6j4O",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RGB values for classes we consider 'Suitable' (Class 1)\n",
        "SUITABLE_RGB_VALUES = [\n",
        "    (255, 255, 0),  # Agriculture land\n",
        "    (255, 0, 255),  # Rangeland\n",
        "    (255, 255, 255),# Barren land\n",
        "    (60, 16, 152),  # Building\n",
        "    (132, 41, 246)  # Unpaved land\n",
        "]"
      ],
      "metadata": {
        "id": "Or0VPK0E7bjU"
      },
      "id": "Or0VPK0E7bjU",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = SolarPanelDataset(train_imgs, train_masks, SUITABLE_RGB_VALUES,  image_transforms, mask_transforms)\n",
        "train_loader = SolarPanelDataset(val_imgs, val_masks, SUITABLE_RGB_VALUES,  image_transforms, mask_transforms)\n",
        "\n",
        "val_loader = DataLoader(val_loader, batch_size=20, shuffle=False)\n",
        "train_loader = DataLoader(train_loader, batch_size=20, shuffle=True)"
      ],
      "metadata": {
        "id": "c9LRSwLP7Izf"
      },
      "id": "c9LRSwLP7Izf",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "90aqShfs7QBS"
      },
      "id": "90aqShfs7QBS"
    },
    {
      "cell_type": "code",
      "source": [
        "## ARCHITECTURE ##\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Block: (Conv -> BN -> ReLU) * 2\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder Block: ConvBlock -> MaxPool\n",
        "    Returns both ConvBlock output (skip) and MaxPool output.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = self.conv_block(x)\n",
        "        pooled = self.pool(skip)\n",
        "        return skip, pooled\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder Block: ConvTranspose -> Concat -> ConvBlock\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        # Upsamples by a factor of 2, halving the channels.\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        # ConvBlock takes concatenated input (skip + upconv), so its input channels\n",
        "        # will be out_channels (from skip) + out_channels (from upconv).\n",
        "        self.conv_block = ConvBlock(out_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x, skip_connection):\n",
        "        x = self.upconv(x)\n",
        "\n",
        "        # Ensure spatial dimensions match before concatenating.\n",
        "        # If input sizes are powers of 2, they should match.\n",
        "        # If not, cropping (from skip) or padding (to x) might be needed.\n",
        "        # Here we assume they match or crop the skip connection if necessary.\n",
        "        if x.shape != skip_connection.shape:\n",
        "            # Simple center-cropping (adjust if needed)\n",
        "            diffY = skip_connection.size()[2] - x.size()[2]\n",
        "            diffX = skip_connection.size()[3] - x.size()[3]\n",
        "            skip_connection = skip_connection[:, :, diffY // 2 : skip_connection.size()[2] - diffY // 2 - diffY % 2,\n",
        "                                                diffX // 2 : skip_connection.size()[3] - diffX // 2 - diffX % 2]\n",
        "\n",
        "        x = torch.cat([x, skip_connection], dim=1) # Concatenate along channel dimension (dim=1)\n",
        "        x = self.conv_block(x)\n",
        "        return x\n",
        "\n",
        "class DeepUnet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_classes=11):\n",
        "        \"\"\"\n",
        "        Initializes the DeepUnet model.\n",
        "\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels (e.g., 3 for RGB).\n",
        "            out_classes (int): Number of output segmentation classes.\n",
        "        \"\"\"\n",
        "        super(DeepUnet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_classes = out_classes\n",
        "\n",
        "        # Encoder Path\n",
        "        self.enc1 = EncoderBlock(in_channels, 64)\n",
        "        self.enc2 = EncoderBlock(64, 128)\n",
        "        self.enc3 = EncoderBlock(128, 256)\n",
        "        self.enc4 = EncoderBlock(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = ConvBlock(512, 1024)\n",
        "\n",
        "        # Decoder Path\n",
        "        self.dec1 = DecoderBlock(1024, 512)\n",
        "        self.dec2 = DecoderBlock(512, 256)\n",
        "        self.dec3 = DecoderBlock(256, 128)\n",
        "        self.dec4 = DecoderBlock(128, 64)\n",
        "\n",
        "        # Output Layer\n",
        "        self.output_conv = nn.Conv2d(64, out_classes, kernel_size=1)\n",
        "\n",
        "        # Optional: Softmax layer. Often omitted if using CrossEntropyLoss,\n",
        "        # which combines LogSoftmax and NLLLoss.\n",
        "        # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the U-Net.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): The input tensor (N, C, H, W).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The output segmentation map (N, out_classes, H, W).\n",
        "        \"\"\"\n",
        "        # Encoder path\n",
        "        s1, p1 = self.enc1(x)\n",
        "        s2, p2 = self.enc2(p1)\n",
        "        s3, p3 = self.enc3(p2)\n",
        "        s4, p4 = self.enc4(p3)\n",
        "\n",
        "        # Bottleneck\n",
        "        b1 = self.bottleneck(p4)\n",
        "\n",
        "        # Decoder path\n",
        "        d1 = self.dec1(b1, s4)\n",
        "        d2 = self.dec2(d1, s3)\n",
        "        d3 = self.dec3(d2, s2)\n",
        "        d4 = self.dec4(d3, s1)\n",
        "\n",
        "        # Output\n",
        "        outputs = self.output_conv(d4)\n",
        "\n",
        "        # Optional: Apply softmax\n",
        "        # outputs = self.softmax(outputs)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "QJ3phlnJ9iHR"
      },
      "id": "QJ3phlnJ9iHR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning algorithm"
      ],
      "metadata": {
        "id": "snPbqh5A5MIg"
      },
      "id": "snPbqh5A5MIg"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration & Constants ---\n",
        "IMG_SIZE = (256, 256)\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 50 # A good starting point, adjust as needed\n",
        "IN_CHANNELS = 3\n",
        "OUT_CLASSES = 2 # 0: Not Suitable, 1: Suitable\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# EarlyStopping Configuration\n",
        "EARLY_STOPPING_PATIENCE = 7 # Number of epochs to wait for improvement before stopping\n",
        "EARLY_STOPPING_MIN_DELTA = 0.0001 # Minimum change in monitored quantity to qualify as improvement\n",
        "\n",
        "# --- 4. Model, Loss, Optimizer ---\n",
        "print(\"Setting up model, loss, and optimizer...\")\n",
        "model = DeepUnet(in_channels=IN_CHANNELS, out_classes=OUT_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# --- 5. Training Loop with EarlyStopping and History ---\n",
        "print(\"Starting training...\")\n",
        "history = {'train_loss': [], 'val_loss': []}\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "best_model_weights = copy.deepcopy(model.state_dict()) # Store best model\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "    for i, (images, masks) in enumerate(train_loader):\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_train_loss += loss.item()\n",
        "        if (i + 1) % 20 == 0: # Print training progress more frequently\n",
        "             print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{len(train_loader)}], Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            running_val_loss += loss.item()\n",
        "    avg_val_loss = running_val_loss / len(val_loader)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"--- Epoch {epoch+1}/{NUM_EPOCHS} Finished ---\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"Epoch Duration: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # EarlyStopping Check\n",
        "    if avg_val_loss < best_val_loss - EARLY_STOPPING_MIN_DELTA:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_no_improve = 0\n",
        "        best_model_weights = copy.deepcopy(model.state_dict())\n",
        "        print(f\"Validation loss improved. Saving model weights.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "    if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "        model.load_state_dict(best_model_weights) # Restore best model weights\n",
        "        break\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"Training finished!\")\n",
        "if epoch < NUM_EPOCHS -1 and epochs_no_improve < EARLY_STOPPING_PATIENCE : # If not early stopped\n",
        "    print(\"Completed all epochs.\")\n",
        "    model.load_state_dict(best_model_weights) # Ensure best model is loaded if early stopping wasn't triggered but patience was > 0\n",
        "\n",
        "# --- 6. Print Loss History ---\n",
        "print(\"\\n--- Training History ---\")\n",
        "for i in range(len(history['train_loss'])):\n",
        "    print(f\"Epoch {i+1}: Train Loss = {history['train_loss'][i]:.4f}, Val Loss = {history['val_loss'][i]:.4f}\")"
      ],
      "metadata": {
        "id": "a3IlxdCJ5S40",
        "outputId": "3a297d77-9221-46b7-9b73-7d2ac2026e49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "a3IlxdCJ5S40",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up model, loss, and optimizer...\n",
            "Starting training...\n",
            "--- Epoch 1/50 Finished ---\n",
            "Train Loss: 0.7818 | Val Loss: 0.6749\n",
            "Epoch Duration: 613.67 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 2/50 Finished ---\n",
            "Train Loss: 0.6248 | Val Loss: 0.6331\n",
            "Epoch Duration: 179.33 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 3/50 Finished ---\n",
            "Train Loss: 0.5680 | Val Loss: 0.5611\n",
            "Epoch Duration: 179.05 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 4/50 Finished ---\n",
            "Train Loss: 0.5083 | Val Loss: 0.5130\n",
            "Epoch Duration: 174.86 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 5/50 Finished ---\n",
            "Train Loss: 0.5259 | Val Loss: 0.4906\n",
            "Epoch Duration: 177.66 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 6/50 Finished ---\n",
            "Train Loss: 0.4511 | Val Loss: 0.4495\n",
            "Epoch Duration: 176.89 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 7/50 Finished ---\n",
            "Train Loss: 0.4638 | Val Loss: 0.4702\n",
            "Epoch Duration: 177.46 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "------------------------------\n",
            "--- Epoch 8/50 Finished ---\n",
            "Train Loss: 0.4897 | Val Loss: 0.4384\n",
            "Epoch Duration: 179.51 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 9/50 Finished ---\n",
            "Train Loss: 0.4659 | Val Loss: 0.4354\n",
            "Epoch Duration: 171.31 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "------------------------------\n",
            "--- Epoch 10/50 Finished ---\n",
            "Train Loss: 0.4697 | Val Loss: 0.4745\n",
            "Epoch Duration: 177.05 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "------------------------------\n",
            "--- Epoch 11/50 Finished ---\n",
            "Train Loss: 0.4557 | Val Loss: 0.4429\n",
            "Epoch Duration: 177.33 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "------------------------------\n",
            "--- Epoch 12/50 Finished ---\n",
            "Train Loss: 0.4404 | Val Loss: 0.4716\n",
            "Epoch Duration: 177.85 seconds\n",
            "Validation loss did not improve for 3 epoch(s).\n",
            "------------------------------\n",
            "--- Epoch 13/50 Finished ---\n",
            "Train Loss: 0.4003 | Val Loss: 1.0669\n",
            "Epoch Duration: 178.50 seconds\n",
            "Validation loss did not improve for 4 epoch(s).\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where you want to save the model\n",
        "model_save_path = \"solar_unet_model.pth\"\n",
        "\n",
        "# Save only the model's state dictionary (recommended for inference/retraining)\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Neural network model saved successfully to {model_save_path}\")"
      ],
      "metadata": {
        "id": "vwfQn9p1HNBc"
      },
      "id": "vwfQn9p1HNBc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretained one"
      ],
      "metadata": {
        "id": "ne6nmqRSMsDF"
      },
      "id": "ne6nmqRSMsDF"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50, fcn_resnet50\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# --- Configuration & Constants ---\n",
        "IMG_SIZE = (256, 256)\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 50\n",
        "IN_CHANNELS = 3\n",
        "OUT_CLASSES = 2  # 0: Not Suitable, 1: Suitable\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Transfer Learning Configuration\n",
        "FREEZE_ENCODER = True  # Whether to freeze encoder weights initially\n",
        "UNFREEZE_AFTER_EPOCHS = 10  # Unfreeze encoder after this many epochs\n",
        "PRETRAINED_LR_FACTOR = 0.1  # Learning rate multiplier for pretrained layers\n",
        "\n",
        "# EarlyStopping Configuration\n",
        "EARLY_STOPPING_PATIENCE = 7\n",
        "EARLY_STOPPING_MIN_DELTA = 0.0001\n",
        "\n",
        "class PretrainedEncoderUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    U-Net with pretrained encoder (ResNet backbone)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, out_classes=2, pretrained=True):\n",
        "        super(PretrainedEncoderUNet, self).__init__()\n",
        "\n",
        "        # Use ResNet50 as encoder backbone\n",
        "        resnet = models.resnet50(pretrained=pretrained)\n",
        "\n",
        "        # Remove the final layers (avgpool and fc)\n",
        "        self.encoder = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "        # Encoder feature dimensions for ResNet50\n",
        "        encoder_dims = [64, 256, 512, 1024, 2048]\n",
        "\n",
        "        # Decoder blocks\n",
        "        self.decoder5 = self._make_decoder_block(2048, 1024)\n",
        "        self.decoder4 = self._make_decoder_block(1024 + 1024, 512)  # +1024 from skip connection\n",
        "        self.decoder3 = self._make_decoder_block(512 + 512, 256)   # +512 from skip connection\n",
        "        self.decoder2 = self._make_decoder_block(256 + 256, 128)   # +256 from skip connection\n",
        "        self.decoder1 = self._make_decoder_block(128 + 64, 64)     # +64 from skip connection\n",
        "\n",
        "        # Final output layer\n",
        "        self.final_conv = nn.Conv2d(64, out_classes, kernel_size=1)\n",
        "\n",
        "        # Store encoder layer references for skip connections\n",
        "        self.encoder_layers = self._get_encoder_layers(resnet)\n",
        "\n",
        "    def _make_decoder_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def _get_encoder_layers(self, resnet):\n",
        "        \"\"\"Extract individual layers from ResNet for skip connections\"\"\"\n",
        "        layers = {}\n",
        "        layers['conv1'] = resnet.conv1\n",
        "        layers['bn1'] = resnet.bn1\n",
        "        layers['relu'] = resnet.relu\n",
        "        layers['maxpool'] = resnet.maxpool\n",
        "        layers['layer1'] = resnet.layer1\n",
        "        layers['layer2'] = resnet.layer2\n",
        "        layers['layer3'] = resnet.layer3\n",
        "        layers['layer4'] = resnet.layer4\n",
        "        return layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path with skip connections\n",
        "        # Initial conv block\n",
        "        x1 = self.encoder_layers['conv1'](x)\n",
        "        x1 = self.encoder_layers['bn1'](x1)\n",
        "        x1 = self.encoder_layers['relu'](x1)\n",
        "        skip1 = x1  # 64 channels\n",
        "\n",
        "        x2 = self.encoder_layers['maxpool'](x1)\n",
        "        x2 = self.encoder_layers['layer1'](x2)\n",
        "        skip2 = x2  # 256 channels\n",
        "\n",
        "        x3 = self.encoder_layers['layer2'](x2)\n",
        "        skip3 = x3  # 512 channels\n",
        "\n",
        "        x4 = self.encoder_layers['layer3'](x3)\n",
        "        skip4 = x4  # 1024 channels\n",
        "\n",
        "        x5 = self.encoder_layers['layer4'](x4)  # 2048 channels (bottleneck)\n",
        "\n",
        "        # Decoder path\n",
        "        d5 = self.decoder5(x5)\n",
        "        d4 = torch.cat([d5, skip4], dim=1)\n",
        "        d4 = self.decoder4(d4)\n",
        "\n",
        "        d3 = torch.cat([d4, skip3], dim=1)\n",
        "        d3 = self.decoder3(d3)\n",
        "\n",
        "        d2 = torch.cat([d3, skip2], dim=1)\n",
        "        d2 = self.decoder2(d2)\n",
        "\n",
        "        d1 = torch.cat([d2, skip1], dim=1)\n",
        "        d1 = self.decoder1(d1)\n",
        "\n",
        "        # Final output\n",
        "        output = self.final_conv(d1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def freeze_encoder(self):\n",
        "        \"\"\"Freeze encoder parameters\"\"\"\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'encoder' in name:\n",
        "                param.requires_grad = False\n",
        "        print(\"Encoder layers frozen\")\n",
        "\n",
        "    def unfreeze_encoder(self):\n",
        "        \"\"\"Unfreeze encoder parameters\"\"\"\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'encoder' in name:\n",
        "                param.requires_grad = True\n",
        "        print(\"Encoder layers unfrozen\")\n",
        "\n",
        "class DeepLabTransferUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Alternative: Use DeepLabV3 as base and modify for binary segmentation\n",
        "    \"\"\"\n",
        "    def __init__(self, out_classes=2):\n",
        "        super(DeepLabTransferUNet, self).__init__()\n",
        "\n",
        "        # Load pretrained DeepLabV3\n",
        "        self.backbone = deeplabv3_resnet50(pretrained=True)\n",
        "\n",
        "        # Modify classifier for our number of classes\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Conv2d(2048, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(256, out_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # Modify auxiliary classifier if it exists\n",
        "        if hasattr(self.backbone, 'aux_classifier'):\n",
        "            self.backbone.aux_classifier = nn.Sequential(\n",
        "                nn.Conv2d(1024, 256, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.Conv2d(256, out_classes, kernel_size=1)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)['out']\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "        \"\"\"Freeze backbone parameters except classifier\"\"\"\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'classifier' not in name:\n",
        "                param.requires_grad = False\n",
        "        print(\"Backbone frozen, only classifier trainable\")\n",
        "\n",
        "    def unfreeze_backbone(self):\n",
        "        \"\"\"Unfreeze all parameters\"\"\"\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True\n",
        "        print(\"All layers unfrozen\")\n",
        "\n",
        "# --- Model Setup with Transfer Learning ---\n",
        "def setup_transfer_learning_model(model_type=\"pretrained_unet\"):\n",
        "    \"\"\"\n",
        "    Setup model with transfer learning\n",
        "    \"\"\"\n",
        "    if model_type == \"pretrained_unet\":\n",
        "        model = PretrainedEncoderUNet(\n",
        "            in_channels=IN_CHANNELS,\n",
        "            out_classes=OUT_CLASSES,\n",
        "            pretrained=True\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        if FREEZE_ENCODER:\n",
        "            model.freeze_encoder()\n",
        "\n",
        "    elif model_type == \"deeplab\":\n",
        "        model = DeepLabTransferUNet(out_classes=OUT_CLASSES).to(DEVICE)\n",
        "        if FREEZE_ENCODER:\n",
        "            model.freeze_backbone()\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Custom Optimizer Setup for Transfer Learning ---\n",
        "def setup_optimizer(model, model_type=\"pretrained_unet\"):\n",
        "    \"\"\"\n",
        "    Setup optimizer with different learning rates for pretrained and new layers\n",
        "    \"\"\"\n",
        "    if model_type == \"pretrained_unet\":\n",
        "        # Different learning rates for encoder and decoder\n",
        "        encoder_params = []\n",
        "        decoder_params = []\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                if 'encoder' in name:\n",
        "                    encoder_params.append(param)\n",
        "                else:\n",
        "                    decoder_params.append(param)\n",
        "\n",
        "        optimizer = optim.Adam([\n",
        "            {'params': encoder_params, 'lr': LEARNING_RATE * PRETRAINED_LR_FACTOR},\n",
        "            {'params': decoder_params, 'lr': LEARNING_RATE}\n",
        "        ])\n",
        "\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "# --- Enhanced Training Loop with Transfer Learning ---\n",
        "def train_with_transfer_learning(model, train_loader, val_loader, model_type=\"pretrained_unet\"):\n",
        "    \"\"\"\n",
        "    Training loop optimized for transfer learning\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = setup_optimizer(model, model_type)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        "    )\n",
        "\n",
        "    print(\"Starting transfer learning training...\")\n",
        "    history = {'train_loss': [], 'val_loss': [], 'lr': []}\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Unfreeze encoder after specified epochs\n",
        "        if epoch == UNFREEZE_AFTER_EPOCHS and FREEZE_ENCODER:\n",
        "            if model_type == \"pretrained_unet\":\n",
        "                model.unfreeze_encoder()\n",
        "            elif model_type == \"deeplab\":\n",
        "                model.unfreeze_backbone()\n",
        "\n",
        "            # Recreate optimizer with unfrozen parameters\n",
        "            optimizer = setup_optimizer(model, model_type)\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        "            )\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "\n",
        "        for i, (images, masks) in enumerate(train_loader):\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Handle different output formats\n",
        "            if isinstance(outputs, dict):\n",
        "                outputs = outputs['out']\n",
        "\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            if (i + 1) % 20 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{len(train_loader)}], \"\n",
        "                      f\"Batch Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_train_loss = running_train_loss / len(train_loader)\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_loader:\n",
        "                images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "\n",
        "                if isinstance(outputs, dict):\n",
        "                    outputs = outputs['out']\n",
        "\n",
        "                loss = criterion(outputs, masks)\n",
        "                running_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = running_val_loss / len(val_loader)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(avg_val_loss)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        history['lr'].append(current_lr)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f\"--- Epoch {epoch+1}/{NUM_EPOCHS} Finished ---\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
        "        print(f\"Epoch Duration: {epoch_time:.2f} seconds\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss - EARLY_STOPPING_MIN_DELTA:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            print(\"Validation loss improved. Saving model weights.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            model.load_state_dict(best_model_weights)\n",
        "            break\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model, history\n",
        "\n",
        "# --- Usage Example ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Choose model type: \"pretrained_unet\" or \"deeplab\"\n",
        "    MODEL_TYPE = \"pretrained_unet\"\n",
        "\n",
        "    # Setup model\n",
        "    model = setup_transfer_learning_model(MODEL_TYPE)\n",
        "\n",
        "    print(f\"Model type: {MODEL_TYPE}\")\n",
        "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # Train model (assuming train_loader and val_loader are defined)\n",
        "    trained_model, history = train_with_transfer_learning(model, train_loader, val_loader, MODEL_TYPE)\n",
        "\n",
        "    # Print training history\n",
        "    print(\"\\n--- Transfer Learning Training History ---\")\n",
        "    for i in range(len(history['train_loss'])):\n",
        "         print(f\"Epoch {i+1}: Train Loss = {history['train_loss'][i]:.4f}, \"\n",
        "               f\"Val Loss = {history['val_loss'][i]:.4f}, LR = {history['lr'][i]:.6f}\")"
      ],
      "metadata": {
        "id": "nOB3zde0Muxv",
        "outputId": "09de2125-8e6c-477d-ab02-d3c5e0c6ab3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nOB3zde0Muxv",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 161MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder layers frozen\n",
            "Model type: pretrained_unet\n",
            "Total parameters: 50,033,474\n",
            "Trainable parameters: 26,525,442\n",
            "Starting transfer learning training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1/50 Finished ---\n",
            "Train Loss: 0.6584 | Val Loss: 0.6819\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 372.66 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 2/50 Finished ---\n",
            "Train Loss: 0.4918 | Val Loss: 0.6162\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 171.36 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 3/50 Finished ---\n",
            "Train Loss: 0.4321 | Val Loss: 0.4583\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 167.91 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 4/50 Finished ---\n",
            "Train Loss: 0.3906 | Val Loss: 0.3840\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 168.69 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 5/50 Finished ---\n",
            "Train Loss: 0.3605 | Val Loss: 0.3589\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 164.87 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 6/50 Finished ---\n",
            "Train Loss: 0.3173 | Val Loss: 0.3502\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 161.11 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 7/50 Finished ---\n",
            "Train Loss: 0.3278 | Val Loss: 0.5347\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 165.13 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 8/50 Finished ---\n",
            "Train Loss: 0.3110 | Val Loss: 0.3670\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 164.71 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 9/50 Finished ---\n",
            "Train Loss: 0.3215 | Val Loss: 0.4042\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 166.20 seconds\n",
            "Validation loss did not improve for 3 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 10/50 Finished ---\n",
            "Train Loss: 0.3197 | Val Loss: 0.3715\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 167.58 seconds\n",
            "Validation loss did not improve for 4 epoch(s).\n",
            "--------------------------------------------------\n",
            "Encoder layers unfrozen\n",
            "--- Epoch 11/50 Finished ---\n",
            "Train Loss: 0.3265 | Val Loss: 0.9988\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 171.68 seconds\n",
            "Validation loss did not improve for 5 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 12/50 Finished ---\n",
            "Train Loss: 0.2683 | Val Loss: 0.3044\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 169.66 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 13/50 Finished ---\n",
            "Train Loss: 0.2350 | Val Loss: 0.2919\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 167.21 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 14/50 Finished ---\n",
            "Train Loss: 0.2425 | Val Loss: 0.2825\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 167.47 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 15/50 Finished ---\n",
            "Train Loss: 0.2531 | Val Loss: 0.3058\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 165.78 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 16/50 Finished ---\n",
            "Train Loss: 0.3196 | Val Loss: 0.3058\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 163.49 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 17/50 Finished ---\n",
            "Train Loss: 0.3904 | Val Loss: 0.2948\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 166.01 seconds\n",
            "Validation loss did not improve for 3 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 18/50 Finished ---\n",
            "Train Loss: 0.2222 | Val Loss: 0.3377\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 164.56 seconds\n",
            "Validation loss did not improve for 4 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 19/50 Finished ---\n",
            "Train Loss: 0.2204 | Val Loss: 0.3465\n",
            "Learning Rate: 0.000010\n",
            "Epoch Duration: 167.26 seconds\n",
            "Validation loss did not improve for 5 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 20/50 Finished ---\n",
            "Train Loss: 0.2172 | Val Loss: 0.3017\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 169.90 seconds\n",
            "Validation loss did not improve for 6 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 21/50 Finished ---\n",
            "Train Loss: 0.2336 | Val Loss: 0.2802\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 169.38 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 22/50 Finished ---\n",
            "Train Loss: 0.3041 | Val Loss: 0.2919\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 171.97 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 23/50 Finished ---\n",
            "Train Loss: 0.2252 | Val Loss: 0.2855\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 169.83 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 24/50 Finished ---\n",
            "Train Loss: 0.2174 | Val Loss: 0.2779\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 171.84 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 25/50 Finished ---\n",
            "Train Loss: 0.2256 | Val Loss: 0.2783\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 170.93 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 26/50 Finished ---\n",
            "Train Loss: 0.1926 | Val Loss: 0.2879\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 167.56 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 27/50 Finished ---\n",
            "Train Loss: 0.2793 | Val Loss: 0.2707\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 172.30 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 28/50 Finished ---\n",
            "Train Loss: 0.2074 | Val Loss: 0.2743\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 164.87 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 29/50 Finished ---\n",
            "Train Loss: 0.1917 | Val Loss: 0.2698\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 161.84 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 30/50 Finished ---\n",
            "Train Loss: 0.2159 | Val Loss: 0.2828\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 165.07 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 31/50 Finished ---\n",
            "Train Loss: 0.3528 | Val Loss: 0.2834\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 166.72 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 32/50 Finished ---\n",
            "Train Loss: 0.2002 | Val Loss: 0.2817\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 165.51 seconds\n",
            "Validation loss did not improve for 3 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 33/50 Finished ---\n",
            "Train Loss: 0.2197 | Val Loss: 0.2723\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 165.69 seconds\n",
            "Validation loss did not improve for 4 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 34/50 Finished ---\n",
            "Train Loss: 0.2042 | Val Loss: 0.2714\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 164.89 seconds\n",
            "Validation loss did not improve for 5 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 35/50 Finished ---\n",
            "Train Loss: 0.3165 | Val Loss: 0.2682\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 170.00 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 36/50 Finished ---\n",
            "Train Loss: 0.2093 | Val Loss: 0.2777\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 164.19 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 37/50 Finished ---\n",
            "Train Loss: 0.1980 | Val Loss: 0.2811\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 165.97 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 38/50 Finished ---\n",
            "Train Loss: 0.2712 | Val Loss: 0.2677\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 169.05 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 39/50 Finished ---\n",
            "Train Loss: 0.1803 | Val Loss: 0.2644\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 165.52 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 40/50 Finished ---\n",
            "Train Loss: 0.1751 | Val Loss: 0.2725\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 161.90 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 41/50 Finished ---\n",
            "Train Loss: 0.2760 | Val Loss: 0.2581\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 167.51 seconds\n",
            "Validation loss improved. Saving model weights.\n",
            "--------------------------------------------------\n",
            "--- Epoch 42/50 Finished ---\n",
            "Train Loss: 0.3032 | Val Loss: 0.2669\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 162.79 seconds\n",
            "Validation loss did not improve for 1 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 43/50 Finished ---\n",
            "Train Loss: 0.2030 | Val Loss: 0.3792\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 163.90 seconds\n",
            "Validation loss did not improve for 2 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 44/50 Finished ---\n",
            "Train Loss: 0.1833 | Val Loss: 0.2626\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 164.07 seconds\n",
            "Validation loss did not improve for 3 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 45/50 Finished ---\n",
            "Train Loss: 0.1914 | Val Loss: 0.2651\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 162.45 seconds\n",
            "Validation loss did not improve for 4 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 46/50 Finished ---\n",
            "Train Loss: 0.1833 | Val Loss: 0.2757\n",
            "Learning Rate: 0.000005\n",
            "Epoch Duration: 163.85 seconds\n",
            "Validation loss did not improve for 5 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 47/50 Finished ---\n",
            "Train Loss: 0.2027 | Val Loss: 0.2906\n",
            "Learning Rate: 0.000003\n",
            "Epoch Duration: 162.29 seconds\n",
            "Validation loss did not improve for 6 epoch(s).\n",
            "--------------------------------------------------\n",
            "--- Epoch 48/50 Finished ---\n",
            "Train Loss: 0.1606 | Val Loss: 0.2595\n",
            "Learning Rate: 0.000003\n",
            "Epoch Duration: 163.68 seconds\n",
            "Validation loss did not improve for 7 epoch(s).\n",
            "Early stopping triggered after 48 epochs.\n",
            "Training finished!\n",
            "\n",
            "--- Transfer Learning Training History ---\n",
            "Epoch 1: Train Loss = 0.6584, Val Loss = 0.6819, LR = 0.000010\n",
            "Epoch 2: Train Loss = 0.4918, Val Loss = 0.6162, LR = 0.000010\n",
            "Epoch 3: Train Loss = 0.4321, Val Loss = 0.4583, LR = 0.000010\n",
            "Epoch 4: Train Loss = 0.3906, Val Loss = 0.3840, LR = 0.000010\n",
            "Epoch 5: Train Loss = 0.3605, Val Loss = 0.3589, LR = 0.000010\n",
            "Epoch 6: Train Loss = 0.3173, Val Loss = 0.3502, LR = 0.000010\n",
            "Epoch 7: Train Loss = 0.3278, Val Loss = 0.5347, LR = 0.000010\n",
            "Epoch 8: Train Loss = 0.3110, Val Loss = 0.3670, LR = 0.000010\n",
            "Epoch 9: Train Loss = 0.3215, Val Loss = 0.4042, LR = 0.000010\n",
            "Epoch 10: Train Loss = 0.3197, Val Loss = 0.3715, LR = 0.000010\n",
            "Epoch 11: Train Loss = 0.3265, Val Loss = 0.9988, LR = 0.000010\n",
            "Epoch 12: Train Loss = 0.2683, Val Loss = 0.3044, LR = 0.000010\n",
            "Epoch 13: Train Loss = 0.2350, Val Loss = 0.2919, LR = 0.000010\n",
            "Epoch 14: Train Loss = 0.2425, Val Loss = 0.2825, LR = 0.000010\n",
            "Epoch 15: Train Loss = 0.2531, Val Loss = 0.3058, LR = 0.000010\n",
            "Epoch 16: Train Loss = 0.3196, Val Loss = 0.3058, LR = 0.000010\n",
            "Epoch 17: Train Loss = 0.3904, Val Loss = 0.2948, LR = 0.000010\n",
            "Epoch 18: Train Loss = 0.2222, Val Loss = 0.3377, LR = 0.000010\n",
            "Epoch 19: Train Loss = 0.2204, Val Loss = 0.3465, LR = 0.000010\n",
            "Epoch 20: Train Loss = 0.2172, Val Loss = 0.3017, LR = 0.000005\n",
            "Epoch 21: Train Loss = 0.2336, Val Loss = 0.2802, LR = 0.000005\n",
            "Epoch 22: Train Loss = 0.3041, Val Loss = 0.2919, LR = 0.000005\n",
            "Epoch 23: Train Loss = 0.2252, Val Loss = 0.2855, LR = 0.000005\n",
            "Epoch 24: Train Loss = 0.2174, Val Loss = 0.2779, LR = 0.000005\n",
            "Epoch 25: Train Loss = 0.2256, Val Loss = 0.2783, LR = 0.000005\n",
            "Epoch 26: Train Loss = 0.1926, Val Loss = 0.2879, LR = 0.000005\n",
            "Epoch 27: Train Loss = 0.2793, Val Loss = 0.2707, LR = 0.000005\n",
            "Epoch 28: Train Loss = 0.2074, Val Loss = 0.2743, LR = 0.000005\n",
            "Epoch 29: Train Loss = 0.1917, Val Loss = 0.2698, LR = 0.000005\n",
            "Epoch 30: Train Loss = 0.2159, Val Loss = 0.2828, LR = 0.000005\n",
            "Epoch 31: Train Loss = 0.3528, Val Loss = 0.2834, LR = 0.000005\n",
            "Epoch 32: Train Loss = 0.2002, Val Loss = 0.2817, LR = 0.000005\n",
            "Epoch 33: Train Loss = 0.2197, Val Loss = 0.2723, LR = 0.000005\n",
            "Epoch 34: Train Loss = 0.2042, Val Loss = 0.2714, LR = 0.000005\n",
            "Epoch 35: Train Loss = 0.3165, Val Loss = 0.2682, LR = 0.000005\n",
            "Epoch 36: Train Loss = 0.2093, Val Loss = 0.2777, LR = 0.000005\n",
            "Epoch 37: Train Loss = 0.1980, Val Loss = 0.2811, LR = 0.000005\n",
            "Epoch 38: Train Loss = 0.2712, Val Loss = 0.2677, LR = 0.000005\n",
            "Epoch 39: Train Loss = 0.1803, Val Loss = 0.2644, LR = 0.000005\n",
            "Epoch 40: Train Loss = 0.1751, Val Loss = 0.2725, LR = 0.000005\n",
            "Epoch 41: Train Loss = 0.2760, Val Loss = 0.2581, LR = 0.000005\n",
            "Epoch 42: Train Loss = 0.3032, Val Loss = 0.2669, LR = 0.000005\n",
            "Epoch 43: Train Loss = 0.2030, Val Loss = 0.3792, LR = 0.000005\n",
            "Epoch 44: Train Loss = 0.1833, Val Loss = 0.2626, LR = 0.000005\n",
            "Epoch 45: Train Loss = 0.1914, Val Loss = 0.2651, LR = 0.000005\n",
            "Epoch 46: Train Loss = 0.1833, Val Loss = 0.2757, LR = 0.000005\n",
            "Epoch 47: Train Loss = 0.2027, Val Loss = 0.2906, LR = 0.000003\n",
            "Epoch 48: Train Loss = 0.1606, Val Loss = 0.2595, LR = 0.000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "class ModelSaver:\n",
        "    \"\"\"\n",
        "    Comprehensive model saving and loading utility\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, save_dir=\"saved_models\"):\n",
        "        self.save_dir = save_dir\n",
        "        self.create_save_directory()\n",
        "\n",
        "    def create_save_directory(self):\n",
        "        \"\"\"Create directory structure for saving models\"\"\"\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(self.save_dir, \"checkpoints\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(self.save_dir, \"best_models\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(self.save_dir, \"final_models\"), exist_ok=True)\n",
        "        print(f\"Model save directory created: {self.save_dir}\")\n",
        "\n",
        "    def save_model_complete(self, model, optimizer, scheduler, history,\n",
        "                           epoch, val_loss, model_name=\"unet_model\",\n",
        "                           save_type=\"final\", additional_info=None):\n",
        "        \"\"\"\n",
        "        Save complete model state with all training information\n",
        "\n",
        "        Args:\n",
        "            model: The neural network model\n",
        "            optimizer: The optimizer used for training\n",
        "            scheduler: Learning rate scheduler (can be None)\n",
        "            history: Training history dictionary\n",
        "            epoch: Current epoch number\n",
        "            val_loss: Current validation loss\n",
        "            model_name: Base name for the model\n",
        "            save_type: Type of save (\"final\", \"best\", \"checkpoint\")\n",
        "            additional_info: Dictionary with additional information to save\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # Determine save path based on type\n",
        "        if save_type == \"checkpoint\":\n",
        "            save_path = os.path.join(self.save_dir, \"checkpoints\", f\"{model_name}_epoch_{epoch}_{timestamp}\")\n",
        "        elif save_type == \"best\":\n",
        "            save_path = os.path.join(self.save_dir, \"best_models\", f\"{model_name}_best_{timestamp}\")\n",
        "        else:  # final\n",
        "            save_path = os.path.join(self.save_dir, \"final_models\", f\"{model_name}_final_{timestamp}\")\n",
        "\n",
        "        # Create directory for this specific save\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        # 1. Save model state dict (most common format)\n",
        "        model_state_path = os.path.join(save_path, f\"{model_name}_state_dict.pth\")\n",
        "        torch.save(model.state_dict(), model_state_path)\n",
        "\n",
        "        # 2. Save complete model (entire model architecture + weights)\n",
        "        complete_model_path = os.path.join(save_path, f\"{model_name}_complete.pth\")\n",
        "        torch.save(model, complete_model_path)\n",
        "\n",
        "        # 3. Save training checkpoint (everything needed to resume training)\n",
        "        checkpoint_data = {\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'epoch': epoch,\n",
        "            'val_loss': val_loss,\n",
        "            'history': history,\n",
        "            'model_class': model.__class__.__name__,\n",
        "            'model_params': self._get_model_params(model),\n",
        "            'timestamp': timestamp,\n",
        "            'save_type': save_type\n",
        "        }\n",
        "\n",
        "        if additional_info:\n",
        "            checkpoint_data.update(additional_info)\n",
        "\n",
        "        checkpoint_path = os.path.join(save_path, f\"{model_name}_checkpoint.pth\")\n",
        "        torch.save(checkpoint_data, checkpoint_path)\n",
        "\n",
        "        # 4. Save model configuration as JSON\n",
        "        config = {\n",
        "            'model_name': model_name,\n",
        "            'model_class': model.__class__.__name__,\n",
        "            'model_parameters': self._get_model_params(model),\n",
        "            'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "            'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "            'epoch': epoch,\n",
        "            'validation_loss': val_loss,\n",
        "            'timestamp': timestamp,\n",
        "            'save_type': save_type,\n",
        "            'pytorch_version': torch.__version__,\n",
        "            'model_size_mb': os.path.getsize(complete_model_path) / (1024 * 1024)\n",
        "        }\n",
        "\n",
        "        if additional_info:\n",
        "            config['additional_info'] = additional_info\n",
        "\n",
        "        config_path = os.path.join(save_path, f\"{model_name}_config.json\")\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(config, f, indent=2, default=str)\n",
        "\n",
        "        # 5. Save training history as JSON\n",
        "        if history:\n",
        "            history_path = os.path.join(save_path, f\"{model_name}_history.json\")\n",
        "            with open(history_path, 'w') as f:\n",
        "                json.dump(history, f, indent=2)\n",
        "\n",
        "        # 6. Save model summary as text\n",
        "        summary_path = os.path.join(save_path, f\"{model_name}_summary.txt\")\n",
        "        self._save_model_summary(model, summary_path, config)\n",
        "\n",
        "        print(f\"Model saved successfully!\")\n",
        "        print(f\"Save location: {save_path}\")\n",
        "        print(f\"Files saved:\")\n",
        "        print(f\"  - State dict: {model_name}_state_dict.pth\")\n",
        "        print(f\"  - Complete model: {model_name}_complete.pth\")\n",
        "        print(f\"  - Checkpoint: {model_name}_checkpoint.pth\")\n",
        "        print(f\"  - Configuration: {model_name}_config.json\")\n",
        "        print(f\"  - History: {model_name}_history.json\")\n",
        "        print(f\"  - Summary: {model_name}_summary.txt\")\n",
        "\n",
        "        return save_path\n",
        "\n",
        "    def save_model_state_only(self, model, model_name=\"unet_model\", save_dir=None):\n",
        "        \"\"\"\n",
        "        Save only the model state dict (lightweight option)\n",
        "        \"\"\"\n",
        "        if save_dir is None:\n",
        "            save_dir = self.save_dir\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"{model_name}_state_{timestamp}.pth\"\n",
        "        filepath = os.path.join(save_dir, filename)\n",
        "\n",
        "        torch.save(model.state_dict(), filepath)\n",
        "        print(f\"Model state dict saved: {filepath}\")\n",
        "        return filepath\n",
        "\n",
        "    def save_onnx_model(self, model, input_shape, model_name=\"unet_model\", save_dir=None):\n",
        "        \"\"\"\n",
        "        Save model in ONNX format for deployment\n",
        "\n",
        "        Args:\n",
        "            model: PyTorch model\n",
        "            input_shape: Tuple of input dimensions (batch_size, channels, height, width)\n",
        "            model_name: Name for the model\n",
        "            save_dir: Directory to save (optional)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if save_dir is None:\n",
        "                save_dir = self.save_dir\n",
        "\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"{model_name}_onnx_{timestamp}.onnx\"\n",
        "            filepath = os.path.join(save_dir, filename)\n",
        "\n",
        "            # Create dummy input for tracing\n",
        "            dummy_input = torch.randn(input_shape)\n",
        "\n",
        "            # Export to ONNX\n",
        "            torch.onnx.export(\n",
        "                model,\n",
        "                dummy_input,\n",
        "                filepath,\n",
        "                export_params=True,\n",
        "                opset_version=11,\n",
        "                do_constant_folding=True,\n",
        "                input_names=['input'],\n",
        "                output_names=['output'],\n",
        "                dynamic_axes={\n",
        "                    'input': {0: 'batch_size'},\n",
        "                    'output': {0: 'batch_size'}\n",
        "                }\n",
        "            )\n",
        "\n",
        "            print(f\"ONNX model saved: {filepath}\")\n",
        "            return filepath\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"ONNX export requires 'onnx' package. Install with: pip install onnx\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving ONNX model: {e}\")\n",
        "            return None\n",
        "\n",
        "    def load_model_complete(self, load_path, model_class=None, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Load complete model with all training information\n",
        "\n",
        "        Args:\n",
        "            load_path: Path to the saved model directory or checkpoint file\n",
        "            model_class: Model class (if loading state dict)\n",
        "            device: Device to load model on\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing model, optimizer, scheduler, history, etc.\n",
        "        \"\"\"\n",
        "        if os.path.isdir(load_path):\n",
        "            # Find checkpoint file in directory\n",
        "            checkpoint_files = [f for f in os.listdir(load_path) if f.endswith('_checkpoint.pth')]\n",
        "            if not checkpoint_files:\n",
        "                raise FileNotFoundError(f\"No checkpoint file found in {load_path}\")\n",
        "            checkpoint_path = os.path.join(load_path, checkpoint_files[0])\n",
        "        else:\n",
        "            checkpoint_path = load_path\n",
        "\n",
        "        # Load checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "        print(f\"Loading model from: {checkpoint_path}\")\n",
        "        print(f\"Model class: {checkpoint.get('model_class', 'Unknown')}\")\n",
        "        print(f\"Saved at epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
        "        print(f\"Validation loss: {checkpoint.get('val_loss', 'Unknown')}\")\n",
        "\n",
        "        result = {\n",
        "            'checkpoint_data': checkpoint,\n",
        "            'epoch': checkpoint.get('epoch', 0),\n",
        "            'val_loss': checkpoint.get('val_loss', float('inf')),\n",
        "            'history': checkpoint.get('history', {}),\n",
        "            'model_params': checkpoint.get('model_params', {}),\n",
        "            'timestamp': checkpoint.get('timestamp', 'Unknown')\n",
        "        }\n",
        "\n",
        "        # Try to load the complete model first\n",
        "        if os.path.isdir(load_path):\n",
        "            complete_model_files = [f for f in os.listdir(load_path) if f.endswith('_complete.pth')]\n",
        "            if complete_model_files:\n",
        "                complete_model_path = os.path.join(load_path, complete_model_files[0])\n",
        "                try:\n",
        "                    model = torch.load(complete_model_path, map_location=device)\n",
        "                    result['model'] = model\n",
        "                    print(\"Complete model loaded successfully\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not load complete model: {e}\")\n",
        "\n",
        "        # If complete model loading failed, try to reconstruct from state dict\n",
        "        if 'model' not in result and model_class is not None:\n",
        "            try:\n",
        "                model_params = checkpoint.get('model_params', {})\n",
        "                model = model_class(**model_params)\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "                model.to(device)\n",
        "                result['model'] = model\n",
        "                print(\"Model reconstructed from state dict\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not reconstruct model: {e}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def load_model_state_only(self, filepath, model_class, model_params=None, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Load only model state dict\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to state dict file\n",
        "            model_class: Class of the model\n",
        "            model_params: Parameters to initialize the model\n",
        "            device: Device to load on\n",
        "        \"\"\"\n",
        "        if model_params is None:\n",
        "            model_params = {}\n",
        "\n",
        "        model = model_class(**model_params)\n",
        "        state_dict = torch.load(filepath, map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "        model.to(device)\n",
        "\n",
        "        print(f\"Model state loaded from: {filepath}\")\n",
        "        return model\n",
        "\n",
        "    def _get_model_params(self, model):\n",
        "        \"\"\"Extract model parameters for reconstruction\"\"\"\n",
        "        params = {}\n",
        "\n",
        "        # Try to get common parameters\n",
        "        if hasattr(model, 'in_channels'):\n",
        "            params['in_channels'] = model.in_channels\n",
        "        if hasattr(model, 'out_classes'):\n",
        "            params['out_classes'] = model.out_classes\n",
        "        if hasattr(model, 'num_classes'):\n",
        "            params['num_classes'] = model.num_classes\n",
        "\n",
        "        return params\n",
        "\n",
        "    def _save_model_summary(self, model, filepath, config):\n",
        "        \"\"\"Save model summary as text file\"\"\"\n",
        "        with open(filepath, 'w') as f:\n",
        "            f.write(\"=\" * 50 + \"\\n\")\n",
        "            f.write(\"MODEL SUMMARY\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "            f.write(f\"Model Name: {config['model_name']}\\n\")\n",
        "            f.write(f\"Model Class: {config['model_class']}\\n\")\n",
        "            f.write(f\"Total Parameters: {config['total_parameters']:,}\\n\")\n",
        "            f.write(f\"Trainable Parameters: {config['trainable_parameters']:,}\\n\")\n",
        "            f.write(f\"Model Size: {config['model_size_mb']:.2f} MB\\n\")\n",
        "            f.write(f\"PyTorch Version: {config['pytorch_version']}\\n\")\n",
        "            f.write(f\"Save Timestamp: {config['timestamp']}\\n\")\n",
        "            f.write(f\"Epoch: {config['epoch']}\\n\")\n",
        "            f.write(f\"Validation Loss: {config['validation_loss']}\\n\\n\")\n",
        "\n",
        "            f.write(\"MODEL ARCHITECTURE:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            f.write(str(model) + \"\\n\\n\")\n",
        "\n",
        "            if config.get('model_parameters'):\n",
        "                f.write(\"MODEL PARAMETERS:\\n\")\n",
        "                f.write(\"-\" * 30 + \"\\n\")\n",
        "                for key, value in config['model_parameters'].items():\n",
        "                    f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "# --- Training Integration Functions ---\n",
        "def save_during_training(model, optimizer, scheduler, history, epoch, val_loss,\n",
        "                        best_val_loss, saver, model_name=\"unet_model\"):\n",
        "    \"\"\"\n",
        "    Function to integrate with training loop for automatic saving\n",
        "    \"\"\"\n",
        "    # Save checkpoint every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        saver.save_model_complete(\n",
        "            model, optimizer, scheduler, history, epoch, val_loss,\n",
        "            model_name, save_type=\"checkpoint\"\n",
        "        )\n",
        "\n",
        "    # Save best model when validation improves\n",
        "    if val_loss < best_val_loss:\n",
        "        saver.save_model_complete(\n",
        "            model, optimizer, scheduler, history, epoch, val_loss,\n",
        "            model_name, save_type=\"best\"\n",
        "        )\n",
        "        print(\"New best model saved!\")\n",
        "\n",
        "    return val_loss < best_val_loss\n",
        "\n",
        "def save_final_model(model, optimizer, scheduler, history, epoch, val_loss,\n",
        "                    saver, model_name=\"unet_model\", additional_info=None):\n",
        "    \"\"\"\n",
        "    Save final model after training completion\n",
        "    \"\"\"\n",
        "    print(\"Saving final model...\")\n",
        "\n",
        "    # Add training completion info\n",
        "    final_info = {\n",
        "        'training_completed': True,\n",
        "        'final_epoch': epoch,\n",
        "        'final_val_loss': val_loss\n",
        "    }\n",
        "\n",
        "    if additional_info:\n",
        "        final_info.update(additional_info)\n",
        "\n",
        "    save_path = saver.save_model_complete(\n",
        "        model, optimizer, scheduler, history, epoch, val_loss,\n",
        "        model_name, save_type=\"final\", additional_info=final_info\n",
        "    )\n",
        "\n",
        "    # Also save lightweight state dict\n",
        "    saver.save_model_state_only(model, model_name)\n",
        "\n",
        "    # Save ONNX if possible (assuming standard input size)\n",
        "    try:\n",
        "        saver.save_onnx_model(model, (1, 3, 256, 256), model_name)\n",
        "    except:\n",
        "        print(\"ONNX export skipped (requires onnx package)\")\n",
        "\n",
        "    return save_path\n",
        "\n",
        "# --- Quick Save Functions ---\n",
        "def quick_save_model(model, filename=\"model.pth\"):\n",
        "    \"\"\"Quick save for model state dict\"\"\"\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    print(f\"Model saved: {filename}\")\n",
        "\n",
        "def quick_save_checkpoint(model, optimizer, epoch, loss, filename=\"checkpoint.pth\"):\n",
        "    \"\"\"Quick save for training checkpoint\"\"\"\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"Checkpoint saved: {filename}\")\n",
        "\n",
        "def quick_load_model(model, filename=\"model.pth\", device=\"cpu\"):\n",
        "    \"\"\"Quick load for model state dict\"\"\"\n",
        "    model.load_state_dict(torch.load(filename, map_location=device))\n",
        "    model.to(device)\n",
        "    print(f\"Model loaded: {filename}\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    quick_save_model(model, filename=\"model.pth\")"
      ],
      "metadata": {
        "id": "sD0pGDo2xOsx",
        "outputId": "5526133b-6636-4101-937e-8ebd640ff3c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sD0pGDo2xOsx",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved: model.pth\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}